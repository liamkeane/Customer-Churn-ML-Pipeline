services:
  # MySQL Database
  mysql:
    image: mysql:8.0
    container_name: mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    ports:
      - "3307:3306"   # Expose MySQL on port 3307 to avoid conflict w current local database
    volumes:
      - mysql_data:/var/lib/mysql   # reminder that mysql_data location is chosen by docker (not local to this project)
      - ./sql/schema.sql:/docker-entrypoint-initdb.d/schema.sql  # Initialize telco DB with schema
    networks:
      - telco_network


  # Container for Airflow's metadata db
  postgres:
    container_name: postgres
    image: postgres:13
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    networks:
    - telco_network

  # Container for Airflow's webserver
  webserver:
    container_name: airflow-webserver
    build:
      context: .
      dockerfile: ./docker/airflow/Dockerfile
    restart: always
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=mysecretkey
      - AIRFLOW__CORE__FERNET_KEY=GgyJ5jUehSy2zQqY958eUWW1ezEgNp4OerBy-AKuD14=
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
    ports:
      - "8080:8080"
    command: webserver
    networks:
      - telco_network

  # Container for Airflow's scheduler
  scheduler:
    container_name: airflow-scheduler
    build:
      context: .
      dockerfile: ./docker/airflow/Dockerfile
    restart: always
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=mysecretkey
      - AIRFLOW__CORE__FERNET_KEY=GgyJ5jUehSy2zQqY958eUWW1ezEgNp4OerBy-AKuD14=
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
    command: scheduler
    networks:
      - telco_network

  # https://medium.com/@opcfrance/setting-up-apache-airflow-with-docker-a-comprehensive-guide-with-examples-c041fed1c3f5

  # # Jupyter Lab for development and analysis
  # jupyter:
  #   image: jupyter/datascience-notebook:latest
  #   container_name: jupyter-lab
  #   restart: always
  #   environment:
  #     JUPYTER_ENABLE_LAB: "yes"
  #     JUPYTER_TOKEN: ${JUPYTER_TOKEN}
  #     GRANT_SUDO: "yes"
  #   ports:
  #     - "8888:8888"
  #   volumes:
  #     - ./notebooks:/home/jovyan/work
  #     - ./data:/home/jovyan/data
  #     - jupyter-user-settings:/home/jovyan/.jupyter
  #   networks:
  #     - telco_network
  #   depends_on:
  #     - mysql


  # MLflow for experiment tracking and model management
  # mlflow:
  #   build:
  #     context: .
  #     dockerfile: ./docker/mlflow/Dockerfile
  #   container_name: churn_mlflow
  #   environment:
  #     MLFLOW_BACKEND_STORE_URI: mysql+pymysql://airflow_user:airflow_password@mysql:3306/churn_analytics
  #     MLFLOW_DEFAULT_ARTIFACT_ROOT: /mlflow/artifacts
  #   ports:
  #     - "5000:5000"
  #   volumes:
  #     - mlflow_artifacts:/mlflow/artifacts
  #   depends_on:
  #     mysql:
  #       condition: service_healthy
  #   networks:
  #     - telco_network
  #   command: >
  #     mlflow server
  #     --backend-store-uri mysql+pymysql://airflow_user:airflow_password@mysql:3306/churn_analytics
  #     --default-artifact-root /mlflow/artifacts
  #     --host 0.0.0.0
  #     --port 5000

volumes:
  mysql_data:
  postgres_data:
  # mlflow_artifacts:
  # jupyter-user-settings:

networks:
  telco_network:
    driver: bridge